{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This notebook shows an example of the k-NN algorithm applied to classification of time series data (accelerometer data). We run the knn algorithm with the raw signals and we compare two similarity measures: euclidian distance and Dynamic Time Warping distance that takes into account a lack of synchornisation between two time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the raw accelerometer signals of the first axis x. We cannot use the other axis as the knn algorithm finds the k closest neighbors of a sample according to a distance and it does not make sense to compare x axis signals to y axis signals. Moreover we do not consider the entire dataset (7352 training samples and 2947 test samples) since Dynamic Time Warping Distance becomes extremely time consumming when the number of samples to compare grows.  \n",
    "Each sample of the data set is a 2.56s window of an activity being performed recorded at a 50Hz rate which makes 128 readings per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (368, 128)\n",
      "X_test shape : (148, 128)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../data')\n",
    "\n",
    "n_skip = 20 # We select a substet of the training and test set (one every 20 sample)...\n",
    "\n",
    "X_train = np.loadtxt('X_train.txt')[::n_skip]\n",
    "X_test = np.loadtxt('X_test.txt')[::n_skip]\n",
    "\n",
    "print(\"X_train shape : {}\".format(X_train.shape))\n",
    "print(\"X_test shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the label vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape : (368,)\n",
      "y_test shape : (148,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.loadtxt('y_train.txt')[::n_skip]\n",
    "y_test = np.loadtxt('y_test.txt')[::n_skip]\n",
    "\n",
    "print(\"y_train shape : {}\".format(y_train.shape))\n",
    "print(\"y_test shape : {}\".format(y_test.shape))\n",
    "\n",
    "label_names = ['Walking', 'Walking upstairs', 'Walking downstairs', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Time Warping and Euclidian distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Two functions that computes euclidian distance and Dynamic Time Warping distance between two time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidian_distance(x1,x2):\n",
    "    return np.linalg.norm(x1-x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dynamic Time Warping is a distance measure between tow time series taking into account the fact one might accelerate or decelarate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DTW_distance(x1, x2, w=1000, distance=lambda x1,x2 : abs(x1-x2)):\n",
    "    \"\"\"Computes Dynamic Time Wrapping distance between time series x1 and x2\n",
    "    INPUTS:\n",
    "        -x1 is a (n,) numpy array\n",
    "        -x2 is a (m,) numpy array\n",
    "        -w is the DTW window (type int)\n",
    "    OUTPUTS:\n",
    "        - the DTW distance between x1 and x2 (float)\n",
    "    \"\"\"\n",
    "    # time series lengths\n",
    "    n = x1.shape[0]\n",
    "    m = x2.shape[0]\n",
    "    w = max(w, abs(n-m)) \n",
    "\n",
    "    # Initialiaze distance matrix\n",
    "    DTW = np.zeros((n,m)) \n",
    "    DTW[0,0] = distance(x1[0],x2[0])\n",
    "    for i in range(1,n):\n",
    "        DTW[i,0] = DTW[i-1,0] + distance(x1[i],x2[0])\n",
    "    for j in range(1,m):\n",
    "        DTW[0,j] = DTW[0,j-1] + distance(x1[0],x2[j])\n",
    "\n",
    "    # We fill the rest of the distance matrix\n",
    "    for i in range(1,n):\n",
    "        for j in range(int(max(1,i-w)),min(m,i+w)):\n",
    "            dist = distance(x1[i],x2[j])\n",
    "            DTW[i,j] = dist + min(DTW[i-1,j], DTW[i,j-1], DTW[i-1,j-1])\n",
    "           \n",
    "    return DTW[-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brute force knn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_distance_matrix(X_train, X_test, w=60, distance = euclidian_distance):\n",
    "    \"\"\" This function returns the distance matrix between samples of X_train and X_tes according to a \n",
    "    similarity measure.\n",
    "    INPUTS:\n",
    "        - X_train a (n, p) numpy array with n:number of training samples and m: number of features\n",
    "        - X_test a (m, p) numpy array with m: number of test samples and m as above\n",
    "        - w DTW window\n",
    "        - distance_type the type of distance to consider for the algorithm ['euclidian', 'DTW']\n",
    "    OUTPUTS:\n",
    "        - dis_m a (m,n) numpy array with dist_m[i,j] = distance(X_test[i,:], X_train[j,:])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Distance matrix calculation\n",
    "    n = X_train.shape[0]\n",
    "    m = X_test.shape[0]  \n",
    "    dist_m = np.zeros((m,n))\n",
    "    for row, test_spl in enumerate(X_test):\n",
    "        for col, train_spl in enumerate(X_train):\n",
    "            if distance == euclidian_distance:\n",
    "                dist_row_col = distance(test_spl, train_spl)\n",
    "                dist_m[row,col] = dist_row_col\n",
    "            else:\n",
    "                dist_row_col = distance(test_spl, train_spl, w)\n",
    "                dist_m[row,col] = dist_row_col                    \n",
    "    return dist_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_k_closest(dist_m, y_train, k):\n",
    "    \"\"\" This function returns the most represented label among the k nearest neighbors of each sample from\n",
    "    X_test.\n",
    "    INPUTS:\n",
    "        - dist_m a (m,n) numpy array with dist_m[i,j] = distance(X_test[i,:], X_train[j,:])\n",
    "        - y_train a (n,) numpy array with X_train labels\n",
    "        - k number of neighbors to consider (int)\n",
    "    OUPUTS:\n",
    "        - y_pred a (m,) numpy array of predicted labels for X_test\n",
    "    \"\"\"\n",
    "    knn_indexes = np.argsort(dist_m)[:,:k]\n",
    "    knn_labels = y_train[knn_indexes]\n",
    "    y_pred = mode(knn_labels, axis=1)[0]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN with euclidian distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare the time series based on the euclidian distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.00 min 0.37 s \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dist_m = make_distance_matrix(X_train, X_test)\n",
    "stop = time.time()\n",
    "\n",
    "print(\"Execution time: {:.2f} min {:.2f} s \".format((stop-start) // 60, (stop-start) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "k = 1\n",
      "\n",
      "\n",
      "Test set report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Walking       0.50      0.48      0.49        23\n",
      "  Walking upstairs       0.52      0.68      0.59        25\n",
      "Walking downstairs       0.88      0.30      0.45        23\n",
      "           Sitting       0.43      0.45      0.44        22\n",
      "          Standing       0.41      0.56      0.47        27\n",
      "            Laying       0.44      0.39      0.42        28\n",
      "\n",
      "       avg / total       0.52      0.48      0.48       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "y_pred = find_k_closest(dist_m, y_train, k)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(\"k = {}\".format(k))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Test set report\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_k_best(dist_m, y_train, y_test, k_range=np.arange(1,22)):\n",
    "    k_range = np.arange(1,22) # range of k to test\n",
    "    f1_scores = np.empty(k_range.shape) # we are going to store f1 scores here\n",
    "    # now we loop over k_range and compute f1_scores...\n",
    "    for k in k_range:\n",
    "        y_pred = find_k_closest(dist_m, y_train, k=k)\n",
    "        f1_scores[k-1] = f1_score(y_test, y_pred, average='macro')\n",
    "    return k_range[np.argmax(f1_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "k = 1\n",
      "\n",
      "\n",
      "Test set report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Walking       0.50      0.48      0.49        23\n",
      "  Walking upstairs       0.52      0.68      0.59        25\n",
      "Walking downstairs       0.88      0.30      0.45        23\n",
      "           Sitting       0.43      0.45      0.44        22\n",
      "          Standing       0.41      0.56      0.47        27\n",
      "            Laying       0.44      0.39      0.42        28\n",
      "\n",
      "       avg / total       0.52      0.48      0.48       148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "k = find_k_best(dist_m, y_train, y_test, k_range=np.arange(1,22))\n",
    "y_pred = find_k_closest(dist_m, y_train, k)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(\"k = {}\".format(k))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Test set report\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN with Dynamic Time Warping distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Dynamic Time Warping Distance (DTW) to compare time series. The results are better with this measure due to the nature of the dataset.  \n",
    "\n",
    "First, as explained in the intro, the samples are 2.56s windows of an activity being performed and these windows overlap so the samples do not share a common time stamp. Secondly, if we compare two people starting walking, their paces may be different and their accelerometer recordings are probably not going to be synchornized.\n",
    "  \n",
    "  Dynamic Time Warping can overcome this issue of synchronization by matching points that are not facing each other.\n",
    "  \n",
    "  Now if we compare to the previous cell, the results are around 10% better with DTW but the execution time is almost 24 min while it was under a second with euclidian distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 22.00 min 23.73 s \n"
     ]
    }
   ],
   "source": [
    "w = 1000\n",
    "\n",
    "start = time.time()\n",
    "dist_m_dtw = make_distance_matrix(X_train, X_test, distance=DTW_distance, w=w)\n",
    "stop = time.time()\n",
    "\n",
    "print(\"Execution time: {:.2f} min {:.2f} s \".format((stop-start) // 60, (stop-start) % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "k = 1\n",
      "w = 1000\n",
      "\n",
      "\n",
      "Test set report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Walking       0.79      0.83      0.81        23\n",
      "  Walking upstairs       0.61      0.88      0.72        25\n",
      "Walking downstairs       1.00      0.48      0.65        23\n",
      "           Sitting       0.53      0.41      0.46        22\n",
      "          Standing       0.44      0.59      0.51        27\n",
      "            Laying       0.50      0.43      0.46        28\n",
      "\n",
      "       avg / total       0.64      0.60      0.60       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "y_pred = find_k_closest(dist_m_dtw, y_train, k=k)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(\"k = {}\".format(k))\n",
    "print(\"w = {}\".format(w))\n",
    "print(\"\\n\")\n",
    "print(\"Test set report\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "k = 1\n",
      "\n",
      "\n",
      "Test set report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           Walking       0.79      0.83      0.81        23\n",
      "  Walking upstairs       0.61      0.88      0.72        25\n",
      "Walking downstairs       1.00      0.48      0.65        23\n",
      "           Sitting       0.53      0.41      0.46        22\n",
      "          Standing       0.44      0.59      0.51        27\n",
      "            Laying       0.50      0.43      0.46        28\n",
      "\n",
      "       avg / total       0.64      0.60      0.60       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = find_k_best(dist_m_dtw, y_train, y_test, k_range=np.arange(1,22))\n",
    "y_pred = find_k_closest(dist_m, y_train, k)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(\"k = {}\".format(k))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Test set report\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
